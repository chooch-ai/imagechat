{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cceae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_title': 'Chooch-ImageChat-3', 'model_id': 'Chooch-ImageChat-3', 'prediction': 'GPT4All was trained using a massive curated corpus of assistant interactions, including word problems, story descriptions, multi-turn dialogue, and code. The training data consisted of roughly one million prompt-response pairs, which were collected and curated to ensure a diverse distribution of prompt topics and model responses. The data was then loaded into Atlas for data curation and cleaning, where any examples where GPT-3.5-Turbo failed to respond to prompts or produced malformed output were removed. The final training dataset consisted of 806,199 high-quality prompt-generation pairs. The model was trained using the collected data, and the training process involved four days of work, $800 in GPU costs, and $500 in OpenAI API spend.', 'prediction_type': 'Chooch-ImageChat-3-Document', 'prompt': 'how was GPT4All trained?', 'source_id': 'ce9ff9bd-cae0-46a1-a966-c1fc3a0512d5.pdf', 'source_type': 'document', 'status': 'Successful Prediction'}\n"
     ]
    }
   ],
   "source": [
    "# ImageChat-3 Predict Document\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# change host name as needed\n",
    "host_name = \"https://chat-api.chooch.ai\"\n",
    "\n",
    "def image_chat_predict(model_id, parameters, file_path = \"\", api_key = None):\n",
    " \n",
    "    payload = {\n",
    "      \"parameters\": parameters\n",
    "    }\n",
    "    \n",
    "    parameters = {\"parameters\": parameters, \"model_id\": model_id}\n",
    "    parameters_json =  json.dumps(parameters) \n",
    "    \n",
    "    payload = {'data': parameters_json }\n",
    "\n",
    "    url = \"{}/predict?api_key={}\".format(host_name, api_key)\n",
    "    #-- url = \"{}/predict_image_chat?api_key={}\".format(host_name, api_key)\n",
    "    if file_path == \"\":\n",
    "         # normal post\n",
    "         response = requests.post(url, data=payload)   \n",
    "    else:\n",
    "        # load file and post \n",
    "        file = {'file': open(file_path, 'rb')}\n",
    "        response = requests.post(url, data=payload, files=file) \n",
    "        \n",
    "    json_data = json.loads(response.content)\n",
    "      \n",
    "    return json_data \n",
    "\n",
    "\n",
    "# set parameters\n",
    "parameters = {}\n",
    "\n",
    "# Set prompt, pass prompt empty on first upload\n",
    "prompt = \"how was GPT4All trained?\"\n",
    "parameters[\"prompt\"] = prompt\n",
    "\n",
    "# optional lang \n",
    "# parameters[\"lang\"] = \"es\"\n",
    "# please check langs.txt file\n",
    "\n",
    "# optional maximum new tokens setting\n",
    "#-- parameters[\"max_new_tokens\"] = 512\n",
    "\n",
    "# replace with your own api key. Get our Api Key by siging up to Chooch Vision Studio https://app.chooch.ai/\n",
    "api_key = \"xxxxx-xxxx-xxxx-xxx-xxxxxxxx\"\n",
    "\n",
    "\n",
    "# make prediction\n",
    "file_path = \"files/2023_GPT4All_Technical_Report.pdf\"\n",
    "\n",
    "\n",
    "# set model_id\n",
    "model_id = \"chooch-image-chat-3\"\n",
    "\n",
    "return_val = image_chat_predict(model_id, parameters, file_path = file_path, api_key = api_key)\n",
    "\n",
    "\n",
    "print(return_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddf413d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_title': 'Chooch-ImageChat-3', 'model_id': 'Chooch-ImageChat-3', 'prediction': 'The authors of GPT4All are Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt, and Andriy Mulyar.', 'prediction_type': 'Chooch-ImageChat-3-Document', 'prompt': 'Who are the authors of GPT4All?', 'source_id': 'a0599243-30b6-4714-9806-d14f5b9f0888.pdf', 'source_type': 'document', 'status': 'Successful Prediction'}\n"
     ]
    }
   ],
   "source": [
    "# predict with source_id, continue chat/conversation on source.\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# change host name as needed\n",
    "host_name = \"https://chat-api.chooch.ai\"\n",
    "\n",
    "def image_chat_predict(model_id, parameters, file_path = \"\", api_key = None):\n",
    " \n",
    "    payload = {\n",
    "      \"parameters\": parameters\n",
    "    }\n",
    "    \n",
    "    parameters = {\"parameters\": parameters, \"model_id\": model_id}\n",
    "    parameters_json =  json.dumps(parameters) \n",
    "    \n",
    "    payload = {'data': parameters_json }\n",
    "\n",
    "    url = \"{}/predict?api_key={}\".format(host_name, api_key)\n",
    "    #-- url = \"{}/predict_image_chat?api_key={}\".format(host_name, api_key)\n",
    "    if file_path == \"\":\n",
    "         # normal post\n",
    "         response = requests.post(url, data=payload)   \n",
    "    else:\n",
    "        # load file and post \n",
    "        file = {'file': open(file_path, 'rb')}\n",
    "        response = requests.post(url, data=payload, files=file) \n",
    "        \n",
    "    json_data = json.loads(response.content)\n",
    "      \n",
    "    return json_data \n",
    "\n",
    "\n",
    "\n",
    "# set parameters\n",
    "parameters = {}\n",
    "\n",
    "# Set prommpt, pass prompt empty on first upload\n",
    "prompt = \"Who are the authors of GPT4All?\" \n",
    "parameters[\"prompt\"] = prompt\n",
    "parameters[\"source_id\"] = 'a0599243-30b6-4714-9806-d14f5b9f0888.pdf'\n",
    "\n",
    "# optional lang \n",
    "# parameters[\"lang\"] = \"es\"\n",
    "# please check langs.txt file\n",
    "\n",
    "# optional maximum new tokens setting\n",
    "#-- parameters[\"max_new_tokens\"] = 512\n",
    "\n",
    "\n",
    "# replace with your own api key, user_id. Get our Api Key by siging up to Chooch Vision Studio https://app.chooch.ai/\n",
    "api_key = \"xxxxx-xxxx-xxxx-xxx-xxxxxxxx\"\n",
    "\n",
    "file_path = \"\"\n",
    "\n",
    "\n",
    "# set model_id\n",
    "model_id = \"chooch-image-chat-3\"\n",
    "\n",
    "return_val = image_chat_predict(model_id, parameters, file_path = file_path, api_key = api_key)\n",
    "\n",
    "\n",
    "print(return_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0871c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_title': 'Chooch-ImageChat-3', 'model_id': 'Chooch-ImageChat-3', 'prediction': 'The article discusses the creation of a large language model (LLM) dataset by leveraging three publicly available datasets: LAION OIG, Stack Overflow questions, and Big-science/P3. The authors spent significant time on data preparation and curation, removing examples where the model failed to respond or produced malformed output. They also removed the entire Bigscience/P3 sub-set from the final training dataset due to its very high perplexity on a small number of tasks. The authors find that models finetuned on this collected dataset exhibit much lower perplexity in the Self-Instruct evaluation compared to Alpaca. They release the data and training details in the hopes of accelerating open LLM research, particularly in the domains of alignment and interpretability.', 'prediction_type': 'Chooch-ImageChat-3-Document', 'prompt': 'Summarize This', 'source_id': '8bf1ce62-d5de-4f57-86b9-2340799e0081.pdf', 'source_type': 'document', 'status': 'Successful Prediction'}\n"
     ]
    }
   ],
   "source": [
    "# predict with source_id\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# change host name as needed\n",
    "host_name = \"https://chat-api.chooch.ai\"\n",
    "\n",
    "def image_chat_predict(model_id, parameters, file_path = \"\", api_key = None):\n",
    " \n",
    "    payload = {\n",
    "      \"parameters\": parameters\n",
    "    }\n",
    "    \n",
    "    parameters = {\"parameters\": parameters, \"model_id\": model_id}\n",
    "    parameters_json =  json.dumps(parameters) \n",
    "    \n",
    "    payload = {'data': parameters_json }\n",
    "\n",
    "    url = \"{}/predict?api_key={}\".format(host_name, api_key)\n",
    "    #-- url = \"{}/predict_image_chat?api_key={}\".format(host_name, api_key)\n",
    "    if file_path == \"\":\n",
    "         # normal post\n",
    "         response = requests.post(url, data=payload)   \n",
    "    else:\n",
    "        # load file and post \n",
    "        file = {'file': open(file_path, 'rb')}\n",
    "        response = requests.post(url, data=payload, files=file) \n",
    "        \n",
    "    json_data = json.loads(response.content)\n",
    "      \n",
    "    return json_data \n",
    "\n",
    "\n",
    "\n",
    "# set parameters\n",
    "parameters = {}\n",
    "\n",
    "# Set prommpt, pass prompt empty on first upload\n",
    "prompt = \"Summarize This\"\n",
    "parameters[\"prompt\"] = prompt\n",
    "parameters[\"source\"] = \"https://chooch-share.s3.amazonaws.com/2023_GPT4All_Technical_Report.pdf\"\n",
    "\n",
    "\n",
    "# optional lang \n",
    "# parameters[\"lang\"] = \"es\"\n",
    "# please check langs.txt file\n",
    "\n",
    "# optional maximum new tokens setting\n",
    "#-- parameters[\"max_new_tokens\"] = 512\n",
    "\n",
    "\n",
    "# replace with your own api key, user_id. Get our Api Key by siging up to Chooch Vision Studio https://app.chooch.ai/\n",
    "api_key = \"xxxxx-xxxx-xxxx-xxx-xxxxxxxx\"\n",
    "\n",
    "file_path = \"\"\n",
    "\n",
    "\n",
    "# set model_id\n",
    "model_id = \"chooch-image-chat-3\"\n",
    "\n",
    "return_val = image_chat_predict(model_id, parameters, file_path = file_path, api_key = api_key)\n",
    "\n",
    "\n",
    "print(return_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9654144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
